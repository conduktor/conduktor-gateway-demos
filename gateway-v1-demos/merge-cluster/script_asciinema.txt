

#Conduktor Proxy's merge cluster feature help single kafka clients can work with multiple kafka clusters transparently. 



# We start the environment first.

```bash
cd merge-cluster
```

docker-compose up -d 

# Create topic on backing kafka cluster
# master_topic on master cluster
docker-compose exec kafka-client \
kafka-topics \
--bootstrap-server kafka1_m:9092 \
--create --if-not-exists \
--topic master_topic
# secondary_topic on secondary cluster
docker-compose exec kafka-client \
kafka-topics \
--bootstrap-server kafka1_s1:19092 \
--create --if-not-exists \
--topic secondary_topic

#We need to register topic and cluster id with conduktor-proxy

```bash
docker-compose exec kafka-client curl \
-X POST \
-H "content-type:application/json" \
-H "authorization:Basic bm9uZTpub25l" \
'conduktor-proxy:8888/topicMappings/passThroughTenant/master_topic' \
-d '{ "topicName":"master_topic", "isConcentrated": false, "isCompacted": "false"}'
```

```bash
docker-compose exec kafka-client curl \
--silent \
-H "content-type:application/json" \
-H "authorization:Basic bm9uZTpub25l" \
'conduktor-proxy:8888/topicMappings/passThroughTenant/secondary_topic' \
-d '{ "clusterId" : "cluster1", "topicName":"secondary_topic", "isConcentrated": false, "isCompacted": "false"}'
```

```bash
docker-compose exec kafka-client curl \
-X POST \
-H "content-type:application/json" \
-H "authorization:Basic bm9uZTpub25l" \
'conduktor-proxy:8888/topics/passThroughTenant' -d '{"name":"master_topic"}'
```

```bash
docker-compose exec kafka-client curl \
-X POST \
-H "content-type:application/json" \
-H "authorization:Basic bm9uZTpub25l" \
'conduktor-proxy:8888/topics/passThroughTenant' -d '{"name":"secondary_topic"}'
```

#Let's produce a simple record to the master_topic topic and secondary_topic topic

```bash
echo 'master_topic_record' | docker-compose exec -T kafka-client \
    kafka-console-producer  \
        --bootstrap-server conduktor-proxy:6969 \
        --topic master_topic
```

```bash
echo 'secondary_topic_record' | docker-compose exec -T kafka-client \
    kafka-console-producer  \
        --bootstrap-server conduktor-proxy:6969 \
        --topic secondary_topic
```

# Consume to verify

# Let's consume from proxy first
# master_topic
```bash
docker-compose exec kafka-client \
  kafka-console-consumer \
    --bootstrap-server conduktor-proxy:6969 \
    --topic master_topic \
    --from-beginning \
    --max-messages 1 \
    --property print.headers=true
```
#secondary_topic


```bash
docker-compose exec kafka-client \
  kafka-console-consumer \
    --bootstrap-server conduktor-proxy:6969 \
    --topic secondary_topic \
    --from-beginning \
    --max-messages 1 \
    --property print.headers=true
```

# Now, consume from kafka clusters

# master cluster

```bash
docker-compose exec kafka-client \
  kafka-console-consumer \
    --bootstrap-server kafka1_m:9092 \
    --topic master_topic \
    --from-beginning \
    --max-messages 1 \
    --property print.headers=true
```

# secondary cluster

```bash
docker-compose exec kafka-client \
  kafka-console-consumer \
    --bootstrap-server kafka1_s1:19092 \
    --topic secondary_topic \
    --from-beginning \
    --max-messages 1 \
    --property print.headers=true
```

#Thank for watching!!!