title: Schema Payload Validation for Protocol Buffer
tag: data-quality
ciTags:
  - NON_REGRESSION
services:
  kafka1:
    properties:
      bootstrap.servers: localhost:19092,localhost:19093,localhost:19094
  kafka2:
    properties:
      bootstrap.servers: localhost:19092,localhost:19093,localhost:19094
  kafka3:
    properties:
      bootstrap.servers: localhost:19092,localhost:19093,localhost:19094
  gateway1:
    properties:
      bootstrap.servers: localhost:6969
      gateway.host: http://localhost:8888
  gateway2:
    properties:
      bootstrap.servers: localhost:6969
      gateway.host: http://localhost:8889

actions:
  - type: INTRODUCTION
    title: What is a Schema Payload Validation Policy Interceptor?
    markdown: |
      Avoid outages from missing or badly formatted records, ensure all messages adhere to a schema.
      
      This interceptor also supports validating payload against specific constraints for AvroSchema and JsonSchema.
      
      This is similar to the validations provided by JsonSchema, such as:
      
      - **Number**: `minimum`, `maximum`, `exclusiveMinimum`, `exclusiveMaximum`, `multipleOf`
      - **String**: `minLength`, `maxLength`, `pattern`, `format`
      - **Collections**: `maxItems`, `minItems`
      
      This interceptor also supports validating payload against specific custom constraints `expression`,
      which uses a simple language familiar with devs is [CEL (Common Expression Language)](https://github.com/google/cel-spec)
      
      This interceptor also supports validating payload against specific custom `metadata.rules` object in the schema
      using CEL, too.

  - type: ASCIINEMA

  - type: FILE
    filename: docker-compose.yaml

  - type: DOCKER
    command: docker compose up --detach --wait

  - type: CREATE_VIRTUAL_CLUSTER
    gateway: gateway1
    name: teamA

  - type: CREATE_TOPICS
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    topics:
      - name: topic-protobuf
        replicationFactor: 1
        partitions: 1

  - type: FILE
    title: Review the example protocol buffer schema
    filename: user-schema.proto

  - type: SH
    title: Let's register it to the Schema Registry
    showOutput: true
    script: |
        curl -s \
          http://localhost:8081/subjects/topic-protobuf/versions \
          -X POST \
          -H "Content-Type: application/vnd.schemaregistry.v1+json" \
          --data "{\"schemaType\": \"PROTOBUF\", \"schema\": $(cat user-schema.proto | jq -Rs)}"
    assertOutputContains:
      - '{"id":1}'

  - type: FILE
    title: Review invalid payload
    filename: invalid-payload.json
    markdown: |
      It is a well formed object, but with invalid data

  - type: SH
    title: Let's send invalid data
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    showOutput: true
    script: |
      cat invalid-payload.json | jq -c | \
          kafka-protobuf-console-producer \
              --bootstrap-server ${BOOTSTRAP_SERVERS} \
              --producer.config ${KAFKA_CONFIG_FILE} \
              --topic topic-protobuf \
              --property schema.registry.url=http://localhost:8081 \
              --property value.schema.id=1
    assertOutputDoesNotContain:
      - "org.apache.kafka.common.errors.PolicyViolationException"

  - type: SH
    title: Let's consume it back
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    showOutput: true
    script: |
      kafka-protobuf-console-consumer \
          --bootstrap-server ${BOOTSTRAP_SERVERS} \
          --consumer.config ${KAFKA_CONFIG_FILE} \
          --topic topic-protobuf \
          --from-beginning \
          --timeout-ms 3000
    markdown: |
      That's pretty bad, you are going to propagate wrong data within your system!

  - type: ADD_INTERCEPTOR
    markdown: |
      Add Schema Payload Validation Policy Interceptor
    gateway: gateway1
    vcluster: teamA
    name: guard-schema-payload-validate
    interceptor:
      "pluginClass": "io.conduktor.gateway.interceptor.safeguard.SchemaPayloadValidationPolicyPlugin"
      "priority": "100"
      "config": {
        "schemaRegistryConfig": {
          "host": "http://schema-registry:8081"
        },
        "topic": "topic-.*",
        "schemaIdRequired": true,
        "validateSchema": true,
        "action": "BLOCK"
      }

  - type: LIST_INTERCEPTORS
    gateway: gateway1
    vcluster: teamA
    assertSize: 1
    assertNames:
      - guard-schema-payload-validate

  - type: FILE
    title: Review the protocol buffer schema with validation rules
    filename: user-schema-with-validation-rules.proto
    markdown: |
      We are adding data contract within our schema by adding `"minLength": 5, "maxLength": 15` or `"format": "email"`

  - type: SH
    title: Let's update the schema with our validation rules
    showOutput: true
    script: |
      curl -s \
        http://localhost:8081/subjects/topic-protobuf/versions \
        -X POST \
        -H "Content-Type: application/vnd.schemaregistry.v1+json" \
        --data "{\"schemaType\": \"PROTOBUF\", \"schema\": $(cat user-schema-with-validation-rules.proto  | jq -Rs)}"
    assertOutputContains:
      - '{"id":2}'

  - type: SH
    title: Let's asserts number of registered schemas
    showOutput: true
    script: |
      curl -s http://localhost:8081/subjects/topic-protobuf/versions
    assertOutputContains:
      - '[1,2]'

  - type: SH
    title: Let's produce the same invalid payload again
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    showOutput: true
    script: |
      cat invalid-payload.json | jq -c | \
          kafka-protobuf-console-producer \
              --bootstrap-server ${BOOTSTRAP_SERVERS} \
              --producer.config ${KAFKA_CONFIG_FILE} \
              --topic topic-protobuf \
              --property schema.registry.url=http://localhost:8081 \
              --property value.schema.id=2
    assertOutputContains:
      - "org.apache.kafka.common.errors.PolicyViolationException"
    markdown: |
      The payload has been rejected with useful errors
      
      ```
      org.apache.kafka.common.errors.PolicyViolationException: Request parameters do not satisfy the configured policy. 
      Topic 'topic-protobuf' has invalid protobuf schema payload: name length must greater than 2, age must be greater than or equal to 18, Student.name is too short (1 < 3), Student.name does not match expression 'size(name) >= 3 && size(name) <= 50', Student.email does not match format 'email', Student.email does not match expression 'email.contains('foo')', Student.Address.street is too long (56 > 10), Student.Address.street does not match expression 'size(street) >= 5 && size(street) <= 10', Student.Address.city is too short (0 < 2), Student.address does not match expression 'size(address.street) >= 5 && address.street.contains('paris') || address.city == 'paris'', Student.hobbies has too few items (1 < 2), Student.hobbies does not match expression 'size(hobbies) >= 2', Student.Friend.age is greater than 10, Student.Friend.age does not match expression 'age >= 2 && age <= 10', Student.Friend.name is too long (11 > 10), Student.Friend.name does not match expression 'size(name) >= 3 && size(name) <= 10', Student.Friend.age is greater than 10, Student.Friend.age does not match expression 'age >= 2 && age <= 10'
      ```

  - type: AUDITLOG
    title: Check in the audit log that message was denied
    kafka: kafka1
    pipeCommand: \| jq 'select(.type=="SAFEGUARD" and .eventData.plugin=="io.conduktor.gateway.interceptor.safeguard.SchemaPayloadValidationPolicyPlugin")'
    assertions:
      - description: Confirm SchemaPayloadValidationPolicyPlugin audit has blocked commit
        value:
          operator: containsIgnoreCase
          expected: Topic 'topic-protobuf' has invalid protobuf schema payload

  - type: SH
    title: Let's now produce a valid payload
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    showOutput: true
    script: |
      cat valid-payload.json | jq -c | \
          kafka-protobuf-console-producer \
              --bootstrap-server ${BOOTSTRAP_SERVERS} \
              --producer.config ${KAFKA_CONFIG_FILE} \
              --topic topic-protobuf \
              --property schema.registry.url=http://localhost:8081 \
              --property value.schema.id=2
    assertOutputDoesNotContain:
      - "org.apache.kafka.common.errors.PolicyViolationException"

  - type: SH
    title: And consume it back
    kafka: teamA
    kafkaConfig: teamA-sa.properties
    showOutput: true
    script: |
        kafka-protobuf-console-consumer \
            --bootstrap-server ${BOOTSTRAP_SERVERS} \
            --consumer.config ${KAFKA_CONFIG_FILE} \
            --topic topic-protobuf \
            --from-beginning \
            --timeout-ms 3000

  - type: DOCKER
    command: docker compose down --volumes

  - type: CONCLUSION
    markdown: |
      You can enrich your existing schema to add even more data quality to your systems!
